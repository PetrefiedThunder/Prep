# Kubernetes CronJob for Automated Database Backups
#
# This CronJob runs daily at 2 AM UTC to create full database backups
# and upload them to S3-compatible storage (MinIO/AWS S3)
#
# Deploy with: kubectl apply -f k8s/backup-cronjob.yaml
#
# Prerequisites:
# - Secret 'db-credentials' with DATABASE_URL
# - Secret 'backup-credentials' with S3 access keys
# - ConfigMap 'backup-config' with retention settings

apiVersion: v1
kind: Secret
metadata:
  name: backup-credentials
  namespace: prep
  labels:
    app: prep
    component: backup
type: Opaque
stringData:
  # Replace with actual values in production
  AWS_ACCESS_KEY_ID: "your-access-key"
  AWS_SECRET_ACCESS_KEY: "your-secret-key"
  S3_ENDPOINT: "s3.amazonaws.com"  # or minio endpoint
  S3_BUCKET: "prep-backups"

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: backup-config
  namespace: prep
  labels:
    app: prep
    component: backup
data:
  # Retention periods
  RETENTION_DAYS: "30"
  RETENTION_WEEKLY: "12"
  RETENTION_MONTHLY: "12"

  # Backup script
  backup.sh: |
    #!/bin/bash
    set -euo pipefail

    echo "Starting database backup at $(date -u +%Y-%m-%dT%H:%M:%SZ)"

    # Configuration
    TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)
    DAY_OF_WEEK=$(date +%u)
    DAY_OF_MONTH=$(date +%d)
    BACKUP_FILE="prep_backup_${TIMESTAMP}.sql.gz"

    # Create backup
    echo "Creating database dump..."
    pg_dump "${DATABASE_URL}" | gzip > "/tmp/${BACKUP_FILE}"
    BACKUP_SIZE=$(du -h "/tmp/${BACKUP_FILE}" | cut -f1)
    echo "Backup created: ${BACKUP_FILE} (${BACKUP_SIZE})"

    # Upload to S3
    echo "Uploading to S3..."
    if [ -n "${S3_ENDPOINT}" ] && [ "${S3_ENDPOINT}" != "s3.amazonaws.com" ]; then
      ENDPOINT_FLAG="--endpoint-url=https://${S3_ENDPOINT}"
    else
      ENDPOINT_FLAG=""
    fi

    # Daily backup
    aws s3 cp ${ENDPOINT_FLAG} "/tmp/${BACKUP_FILE}" "s3://${S3_BUCKET}/daily/${BACKUP_FILE}"

    # Weekly backup (on Sundays)
    if [ "${DAY_OF_WEEK}" = "7" ]; then
      echo "Creating weekly backup copy..."
      aws s3 cp ${ENDPOINT_FLAG} "/tmp/${BACKUP_FILE}" "s3://${S3_BUCKET}/weekly/${BACKUP_FILE}"
    fi

    # Monthly backup (on 1st of month)
    if [ "${DAY_OF_MONTH}" = "01" ]; then
      echo "Creating monthly backup copy..."
      aws s3 cp ${ENDPOINT_FLAG} "/tmp/${BACKUP_FILE}" "s3://${S3_BUCKET}/monthly/${BACKUP_FILE}"
    fi

    # Cleanup old backups
    echo "Cleaning up old backups..."

    # Remove daily backups older than RETENTION_DAYS
    CUTOFF_DAILY=$(date -d "-${RETENTION_DAYS} days" +%Y%m%d)
    aws s3 ls ${ENDPOINT_FLAG} "s3://${S3_BUCKET}/daily/" | while read -r line; do
      file=$(echo "$line" | awk '{print $4}')
      if [ -n "$file" ]; then
        file_date=$(echo "$file" | grep -oP '\d{8}' | head -1)
        if [ -n "$file_date" ] && [ "$file_date" -lt "$CUTOFF_DAILY" ]; then
          echo "Removing old daily backup: $file"
          aws s3 rm ${ENDPOINT_FLAG} "s3://${S3_BUCKET}/daily/$file"
        fi
      fi
    done

    # Remove weekly backups older than RETENTION_WEEKLY weeks
    CUTOFF_WEEKLY=$(date -d "-$((RETENTION_WEEKLY * 7)) days" +%Y%m%d)
    aws s3 ls ${ENDPOINT_FLAG} "s3://${S3_BUCKET}/weekly/" | while read -r line; do
      file=$(echo "$line" | awk '{print $4}')
      if [ -n "$file" ]; then
        file_date=$(echo "$file" | grep -oP '\d{8}' | head -1)
        if [ -n "$file_date" ] && [ "$file_date" -lt "$CUTOFF_WEEKLY" ]; then
          echo "Removing old weekly backup: $file"
          aws s3 rm ${ENDPOINT_FLAG} "s3://${S3_BUCKET}/weekly/$file"
        fi
      fi
    done

    # Clean up local file
    rm -f "/tmp/${BACKUP_FILE}"

    echo "Backup completed successfully at $(date -u +%Y-%m-%dT%H:%M:%SZ)"

---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: database-backup
  namespace: prep
  labels:
    app: prep
    component: backup
spec:
  # Run daily at 2 AM UTC
  schedule: "0 2 * * *"

  # Timezone (requires Kubernetes 1.27+)
  # timeZone: "UTC"

  # Don't start if previous job is still running
  concurrencyPolicy: Forbid

  # Keep last 3 successful and 1 failed job for debugging
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1

  # Start within 1 hour of scheduled time
  startingDeadlineSeconds: 3600

  jobTemplate:
    spec:
      # Retry up to 3 times on failure
      backoffLimit: 3

      # Timeout after 1 hour
      activeDeadlineSeconds: 3600

      template:
        metadata:
          labels:
            app: prep
            component: backup
          annotations:
            # Prevent service mesh injection for backup job
            sidecar.istio.io/inject: "false"
        spec:
          restartPolicy: OnFailure

          # Service account with minimal permissions
          serviceAccountName: backup-sa

          # Security context
          securityContext:
            runAsNonRoot: true
            runAsUser: 1000
            fsGroup: 1000

          containers:
            - name: backup
              image: postgres:15-alpine

              # Resource limits
              resources:
                requests:
                  memory: "256Mi"
                  cpu: "100m"
                limits:
                  memory: "1Gi"
                  cpu: "500m"

              # Security context for container
              securityContext:
                allowPrivilegeEscalation: false
                readOnlyRootFilesystem: false
                capabilities:
                  drop:
                    - ALL

              # Environment variables
              env:
                - name: DATABASE_URL
                  valueFrom:
                    secretKeyRef:
                      name: db-credentials
                      key: DATABASE_URL

                - name: AWS_ACCESS_KEY_ID
                  valueFrom:
                    secretKeyRef:
                      name: backup-credentials
                      key: AWS_ACCESS_KEY_ID

                - name: AWS_SECRET_ACCESS_KEY
                  valueFrom:
                    secretKeyRef:
                      name: backup-credentials
                      key: AWS_SECRET_ACCESS_KEY

                - name: S3_ENDPOINT
                  valueFrom:
                    secretKeyRef:
                      name: backup-credentials
                      key: S3_ENDPOINT

                - name: S3_BUCKET
                  valueFrom:
                    secretKeyRef:
                      name: backup-credentials
                      key: S3_BUCKET

                - name: RETENTION_DAYS
                  valueFrom:
                    configMapKeyRef:
                      name: backup-config
                      key: RETENTION_DAYS

                - name: RETENTION_WEEKLY
                  valueFrom:
                    configMapKeyRef:
                      name: backup-config
                      key: RETENTION_WEEKLY

                - name: RETENTION_MONTHLY
                  valueFrom:
                    configMapKeyRef:
                      name: backup-config
                      key: RETENTION_MONTHLY

              # Mount backup script
              volumeMounts:
                - name: backup-script
                  mountPath: /scripts
                - name: tmp
                  mountPath: /tmp

              # Run backup script
              command:
                - /bin/bash
                - /scripts/backup.sh

          volumes:
            - name: backup-script
              configMap:
                name: backup-config
                items:
                  - key: backup.sh
                    path: backup.sh
                    mode: 0755
            - name: tmp
              emptyDir: {}

---
# Service account for backup job
apiVersion: v1
kind: ServiceAccount
metadata:
  name: backup-sa
  namespace: prep
  labels:
    app: prep
    component: backup

---
# NetworkPolicy to allow backup job to connect to database
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-backup-to-db
  namespace: prep
spec:
  podSelector:
    matchLabels:
      component: backup
  policyTypes:
    - Egress
  egress:
    # Allow PostgreSQL connection
    - to:
        - podSelector:
            matchLabels:
              app: postgres
      ports:
        - protocol: TCP
          port: 5432
    # Allow S3/MinIO connection
    - to:
        - namespaceSelector: {}
      ports:
        - protocol: TCP
          port: 443
        - protocol: TCP
          port: 9000
    # Allow DNS resolution
    - to:
        - namespaceSelector: {}
      ports:
        - protocol: UDP
          port: 53
